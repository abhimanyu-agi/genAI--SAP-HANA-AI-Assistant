{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#Install Open AI"
      ],
      "metadata": {
        "id": "wYOndbp-dHcQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "N2QqCTgdjBwG",
        "outputId": "5b7211e5-fa9b-493d-bd0b-1755d32e87b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: OpenAi in /usr/local/lib/python3.11/dist-packages (1.75.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from OpenAi) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from OpenAi) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from OpenAi) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from OpenAi) (0.9.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from OpenAi) (2.11.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from OpenAi) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from OpenAi) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from OpenAi) (4.13.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->OpenAi) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->OpenAi) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->OpenAi) (1.0.8)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->OpenAi) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->OpenAi) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->OpenAi) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->OpenAi) (0.4.0)\n"
          ]
        }
      ],
      "source": [
        "pip install OpenAi\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "from google.colab import userdata\n",
        "import os"
      ],
      "metadata": {
        "id": "A7M-iBDXjExi"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "client = OpenAI(api_key=\"Your API OpenAI Key\")"
      ],
      "metadata": {
        "id": "Izv3s6zujGjG"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit pyngrok openai hana-ml pandas matplotlib seaborn requests -q"
      ],
      "metadata": {
        "id": "Sfl5f2bsjHJ0",
        "collapsed": true
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import json\n",
        "import requests\n",
        "import os\n",
        "import time\n",
        "import pandas as pd\n",
        "from hana_ml.dataframe import ConnectionContext\n",
        "import matplotlib\n",
        "matplotlib.use('Agg')\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from openai import OpenAI\n",
        "import subprocess\n",
        "from google.colab import userdata\n",
        "\n",
        "\n",
        "\n",
        "HANA_ADDRESS = '434f8d46-16a2-4bb2-856d-a369e7a0b0c6.hana.trial-us10.hanacloud.ondemand.com'\n",
        "HANA_PORT = 443\n",
        "HANA_USER = \"DBADMIN\"\n",
        "HANA_PASSWORD = \"Your Password\"\n",
        "OPENAI_API_KEY = 'Your Open API Key'\n",
        "\n",
        "\n",
        "hana_conn_error = None\n",
        "openai_client_error = None\n",
        "HANA_CONNECTION = None\n",
        "client = None\n",
        "\n",
        "## Check if SAP HANA And Open AI Connections are working fine or not\n",
        "try:\n",
        "    HANA_CONNECTION = ConnectionContext(address=HANA_ADDRESS,\n",
        "                                        port=HANA_PORT,\n",
        "                                        user=HANA_USER,\n",
        "                                        password=HANA_PASSWORD)\n",
        "    HANA_CONNECTION.connection.isconnected()\n",
        "\n",
        "except Exception as e:\n",
        "    hana_conn_error = e\n",
        "    HANA_CONNECTION = None\n",
        "\n",
        "try:\n",
        "    client = OpenAI(api_key=\"Your API OpenAI Key\")\n",
        "    client.models.list()\n",
        "\n",
        "except Exception as e:\n",
        "    openai_client_error = e\n",
        "    client = None\n",
        "\n",
        "# --- Tool Functions ---\n",
        "\n",
        "# Agent 1 : Query SAP HANA Database\n",
        "\n",
        "def query_hana(sql_query: str) -> pd.DataFrame | str:\n",
        "    \"\"\"Run SQL on HANA and return a DataFrame or error message.\"\"\"\n",
        "    if HANA_CONNECTION is None:\n",
        "        return f\"Error: HANA Connection not established. Cannot execute query.\"\n",
        "\n",
        "    st.info(f\"üì° Connecting to HANA Cloud (executing query)...\")\n",
        "    try:\n",
        "        result_df = HANA_CONNECTION.sql(sql_query).collect()\n",
        "        if not isinstance(result_df, pd.DataFrame):\n",
        "             st.error(\"‚ùå Error: HANA query did not return a Pandas DataFrame.\")\n",
        "             return \"Error: Query did not return expected data format.\"\n",
        "\n",
        "        st.success(f\"‚úÖ Query executed successfully. Rows returned: {len(result_df)}\")\n",
        "        return result_df\n",
        "\n",
        "    except Exception as e:\n",
        "        st.error(f\"‚ùå HANA Query Failed: {e}\")\n",
        "        error_message = f\"Error executing HANA query: {str(e)}\"\n",
        "\n",
        "        if 'inconsistent datatype' in str(e).lower() and ('sum' in str(e).lower() or 'avg' in str(e).lower()):\n",
        "            error_message += \"\\n   Hint: This might be due to applying SUM/AVG to a non-numeric column (like 'Amount' if it's text). Consider using CAST(\\\"Amount\\\" AS DECIMAL) in the SQL.\"\n",
        "        return error_message\n",
        "\n",
        "# Agent 2 : Create chart out of SQL generated by Agent 1\n",
        "\n",
        "def create_chart(data: pd.DataFrame, chart_params: dict) -> str:\n",
        "    \"\"\"Creates a chart from a DataFrame based on provided parameters.\n",
        "       Attempts to auto-detect and apply 'hue' for comparisons if missed by AI.\"\"\"\n",
        "\n",
        "    required_params = ['chart_type', 'x_col', 'y_col', 'title']\n",
        "    chart_type = chart_params.get('chart_type')\n",
        "    x_col = chart_params.get('x_col')\n",
        "    y_col = chart_params.get('y_col')\n",
        "    title = chart_params.get('title')\n",
        "    hue_col = chart_params.get('hue_col', None)\n",
        "\n",
        "\n",
        "    if not all([chart_type, x_col, y_col, title]):\n",
        "        missing = [k for k in required_params if not chart_params.get(k)]\n",
        "        return f\"Error: Missing params: {', '.join(missing)}\"\n",
        "\n",
        "\n",
        "    if not isinstance(data, pd.DataFrame) or data.empty: return \"Error: No data for chart.\"\n",
        "    if x_col not in data.columns: return f\"Error: X-col '{x_col}' missing. Cols: {list(data.columns)}\"\n",
        "    if y_col not in data.columns: return f\"Error: Y-col '{y_col}' missing. Cols: {list(data.columns)}\"\n",
        "    if hue_col and hue_col not in data.columns: return f\"Error: Hue-col '{hue_col}' missing. Cols: {list(data.columns)}\"\n",
        "\n",
        "\n",
        "\n",
        "    if hue_col is None and chart_type.lower() in ['line', 'bar'] and len(data.columns) > 2:\n",
        "\n",
        "        potential_hue_cols = []\n",
        "        for col in data.columns:\n",
        "\n",
        "            if col != x_col and col != y_col:\n",
        "                 dtype_str = str(data[col].dtype).lower()\n",
        "                 if 'object' in dtype_str or 'category' in dtype_str or 'string' in dtype_str:\n",
        "                     unique_count = data[col].nunique()\n",
        "                     if 1 < unique_count <= 10:\n",
        "                         potential_hue_cols.append(col)\n",
        "\n",
        "\n",
        "        best_potential_hue = None\n",
        "        if potential_hue_cols:\n",
        "\n",
        "            preferred_cols = [\"Product\", \"Country\", \"Sales Person\"]\n",
        "            for pref_col in preferred_cols:\n",
        "                if pref_col in potential_hue_cols: best_potential_hue = pref_col; break\n",
        "            if not best_potential_hue: best_potential_hue = potential_hue_cols[0]\n",
        "\n",
        "\n",
        "        if best_potential_hue:\n",
        "            hue_col = best_potential_hue\n",
        "            st.warning(f\"ü§ñ Auto-applied category distinction using column: '{hue_col}'\", icon=\"‚ö†Ô∏è\")\n",
        "\n",
        "    try:\n",
        "        data_copy = data.copy()\n",
        "        if data_copy[y_col].dtype == 'object':\n",
        "\n",
        "            data_copy[y_col] = pd.to_numeric(data_copy[y_col].astype(str).str.replace(',', '', regex=False), errors='coerce')\n",
        "            if data_copy[y_col].isnull().any():\n",
        "                st.warning(f\"‚ö†Ô∏è Some values in '{y_col}' ignored (non-numeric).\")\n",
        "                data_copy.dropna(subset=[y_col], inplace=True)\n",
        "                if data_copy.empty: return f\"Error: No valid numeric data in '{y_col}'.\"\n",
        "        data = data_copy\n",
        "\n",
        "    except Exception as convert_e: st.warning(f\"‚ö†Ô∏è Y-col conversion issue: {convert_e}\")\n",
        "\n",
        "## Data Plotting\n",
        "    fig, ax = plt.subplots(figsize=(10, 5.5))\n",
        "    try:\n",
        "        plt.style.use('seaborn-v0_8-darkgrid')\n",
        "        ax.set_facecolor('#2B3F55'); fig.patch.set_facecolor('#1E2A3A')\n",
        "        ax.tick_params(colors='white'); ax.xaxis.label.set_color('white')\n",
        "        ax.yaxis.label.set_color('white'); ax.title.set_color('white')\n",
        "\n",
        "        plot_params = {'data': data, 'x': x_col, 'y': y_col, 'ax': ax}\n",
        "        if hue_col:\n",
        "            plot_params['hue'] = hue_col\n",
        "            if chart_type.lower() == 'bar': plot_params['dodge'] = True\n",
        "            if chart_type.lower() == 'line': plot_params['marker'] = 'o'\n",
        "\n",
        "\n",
        "\n",
        "        if chart_type.lower() == 'bar': sns.barplot(**plot_params)\n",
        "        elif chart_type.lower() == 'line': sns.lineplot(**plot_params)\n",
        "        else: plt.close(fig); return f\"Error: Unsupported chart: '{chart_type}'.\"\n",
        "\n",
        "        ax.set_title(title, fontsize=14, fontweight='bold')\n",
        "        ax.set_xlabel(x_col, fontsize=12)\n",
        "        ax.set_ylabel(y_col, fontsize=12)\n",
        "        if hue_col:\n",
        "            legend = ax.legend(title=hue_col, bbox_to_anchor=(1.05, 1), loc='upper left', facecolor='#2B3F55', edgecolor='white')\n",
        "            plt.setp(legend.get_texts(), color='white')\n",
        "            plt.setp(legend.get_title(), color='white', fontweight='bold')\n",
        "        if data[x_col].nunique() > 8 and data[x_col].dtype == 'object': plt.setp(ax.get_xticklabels(), rotation=45, ha='right')\n",
        "        else: plt.setp(ax.get_xticklabels(), rotation=0)\n",
        "        plt.tight_layout(rect=[0, 0, 0.85, 1])\n",
        "        safe_title = \"\".join(c if c.isalnum() else \"_\" for c in title)\n",
        "        if not os.path.exists(\"charts\"): os.makedirs(\"charts\")\n",
        "        chart_filename = f\"charts/chart_{safe_title}_{int(time.time())}.png\"\n",
        "        plt.savefig(chart_filename, bbox_inches='tight', facecolor=fig.get_facecolor(), transparent=False)\n",
        "        plt.close(fig)\n",
        "        st.success(f\"‚úÖ Chart saved as {chart_filename}\")\n",
        "\n",
        "        return f\"Chart '{title}' created and saved as {chart_filename}\"\n",
        "\n",
        "    except Exception as e:\n",
        "        st.error(f\"‚ùå Error creating chart: {e}\")\n",
        "\n",
        "        st.error(f\"Traceback:\\n{traceback.format_exc()}\")\n",
        "        plt.close(fig)\n",
        "\n",
        "        return f\"Error creating chart: {e}\"\n",
        "\n",
        "# Agent 2 : To call Weather API real time\n",
        "def get_weather(city:str):\n",
        "    \"\"\"Gets the weather for a given city.\"\"\"\n",
        "    st.write(f\"‚õèÔ∏è Tool Called: get_weather, City: {city}\")\n",
        "    url = f\"https://wttr.in/{city}?format=%C+%t\"\n",
        "    try:\n",
        "        response = requests.get(url, timeout=10)\n",
        "        response.raise_for_status()\n",
        "        st.success(f\"‚úÖ Weather data retrieved for {city}\")\n",
        "        return f\"The weather in {city} is {response.text}\"\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        st.error(f\"‚ùå Error fetching weather for {city}: {e}\")\n",
        "        return f\"Error fetching weather for {city}: {e}\"\n",
        "\n",
        "# Agent 3 : To run command in your  current directory\n",
        "def run_command(command: str) -> str:\n",
        "    \"\"\"Executes a shell command.\"\"\"\n",
        "    st.write(f\"‚õèÔ∏è Tool Called: run_command, Command: {command}\")\n",
        "    allowed_commands = ['ls', 'pwd', 'echo']\n",
        "    try:\n",
        "        command_parts = command.strip().split()\n",
        "        if not command_parts:\n",
        "             return \"Error: Empty command provided.\"\n",
        "        command_base = command_parts[0]\n",
        "    except IndexError:\n",
        "        return \"Error: Empty command provided.\"\n",
        "\n",
        "    if command_base not in allowed_commands:\n",
        "         st.warning(f\"‚ùå Blocked unsafe command: {command}\")\n",
        "         return f\"Error: Command '{command_base}' is not allowed.\"\n",
        "    try:\n",
        "        import subprocess\n",
        "        process = subprocess.run(command, shell=True, capture_output=True, text=True, timeout=15, check=False)\n",
        "        output = process.stdout + process.stderr\n",
        "        if process.returncode == 0:\n",
        "            st.success(f\"‚úÖ Command executed successfully.\")\n",
        "            return f\"Command output:\\n'''\\n{output.strip()}\\n'''\"\n",
        "        else:\n",
        "            st.error(f\"‚ùå Command failed with return code {process.returncode}\")\n",
        "            return f\"Command failed (code {process.returncode}):\\n'''\\n{output.strip()}\\n'''\"\n",
        "    except Exception as e:\n",
        "        st.error(f\"‚ùå Error executing command '{command}': {e}\")\n",
        "        return f\"Error executing command: {e}\"\n",
        "\n",
        "## Available Tools\n",
        "\n",
        "available_tools = {\n",
        "    \"get_weather\": {\n",
        "        \"fn\": get_weather,\n",
        "        \"description\": \"Takes a city name and returns the current weather for that city.\"\n",
        "    },\n",
        "    \"run_command\": {\n",
        "        \"fn\": run_command,\n",
        "        \"description\": \"Takes a *safe* shell command string (like 'ls', 'pwd') and executes it, returning the output. Use with caution.\"\n",
        "    },\n",
        "    \"query_hana\": {\n",
        "        \"fn\": query_hana,\n",
        "        \"description\": \"Takes a valid SQL query string for the CHOCOLATE_SALES table. Executes the query against HANA Cloud. Returns the resulting data (as a DataFrame) on success, which is made available for subsequent steps (like charting), or an error message string on failure.\"\n",
        "    },\n",
        "    \"create_chart\": {\n",
        "         \"fn\": create_chart,\n",
        "         \"description\": \"Takes a JSON object input with keys 'chart_type' (string: 'bar' or 'line'), 'x_col' (string: column name for X-axis), 'y_col' (string: column name for Y-axis), and 'title' (string). It uses the data obtained from the *immediately preceding* successful 'query_hana' call to generate and save a chart image. Returns a confirmation message including the filename or an error.\"\n",
        "     }\n",
        "}\n",
        "\n",
        "\n",
        "system_prompt = \"\"\"\n",
        "You are a helpful AI Assistant specialized in resolving user queries using available tools.\n",
        "You operate in four charming steps: Start ‚Üí Plan ‚Üí Action ‚Üí Observe.\n",
        "\n",
        "Your mission: For any user query and available tools, break the problem down into a plan,\n",
        "select the appropriate tool based on your brilliant deduction, call that tool, wait for its result,\n",
        "and finally resolve the user‚Äôs query.\n",
        "\n",
        "---\n",
        "\n",
        "Rules:\n",
        "1. Always follow the strict JSON output format ‚Äî but make it delightful!\n",
        "{\n",
        "  \"step\": \"plan|action|output\",\n",
        "  \"content\": \"Your thought process for plan/output, or empty for action.\",\n",
        "  \"function\": \"tool_name (only if step is action)\",\n",
        "  \"input\": \"tool_input (string for most, JSON object for create_chart - only if step is action)\"\n",
        "}\n",
        "2. Perform only one step at a time, like a graceful ballet.\n",
        "3. Carefully analyze the user query using your sharp wit.\n",
        "4. When using the 'query_hana' tool, generate **SQL for the CHOCOLATE_SALES table** using proper rules and double-quote column names.\n",
        "5. When the user asks for a chart or visualization:\n",
        "   a. First, use 'query_hana' to fetch the necessary aggregated or filtered data. Ensure your SQL query selects the exact columns needed for the chart axes (e.g., month, sales amount).\n",
        "   b. **Crucially, if the request involves comparing multiple categories (like different products, countries, or sales persons) on the *same* chart, your SQL query *must* also select the category column itself (e.g., \"Product\", \"Country\").**\n",
        "   c. Then, in the *next* action step, use the 'create_chart' tool.\n",
        "   d. For 'create_chart', provide a JSON object for the 'input' field containing: 'chart_type', 'x_col', 'y_col', and a descriptive 'title'.\n",
        "   e. **MANDATORY FOR COMPARISONS:** If the query involves comparing categories (see rule 5b), you **MUST** include the 'hue_col' parameter in the 'create_chart' JSON input. Set its value to the name of the category column selected in your SQL (e.g., '\"hue_col\": \"Product\"'). **Failure to include 'hue_col' when comparing categories will result in an incorrect chart.**\n",
        "6.  **IMPORTANT FOR DATA DISPLAY:** When the user asks for data directly (not a chart) and you have successfully run 'query_hana':\n",
        "    a. In your final 'output' step, formulate your response conversationally.\n",
        "    b. Include the exact placeholder '%%DATA_TABLE%%' where the retrieved data should be displayed by the system. **Crucial:** Your *only* way to show the data is to put the literal string '%%DATA_TABLE%%' in your final 'output' step's content. The system will replace this. **Do not** try to list the data yourself or summarize it beyond mentioning the count if relevant. Just use the placeholder.\n",
        "\n",
        "7.**AVOID FULL TABLE QUERIES:** Do **NOT** generate SQL queries that attempt to select all columns ('SELECT *') or many raw columns without any filtering ('WHERE'), aggregation ('SUM', 'COUNT', 'AVG', 'GROUP BY'), or row limitation ('LIMIT').\n",
        "    Queries like 'SELECT * FROM CHOCOLATE_SALES' or 'SELECT \"Sales Person\", \"Country\", \"Product\", \"Date\", \"Amount\", \"Boxes Shipped\" FROM CHOCOLATE_SALES' are **forbidden** as they are inefficient and unhelpful.\n",
        "\n",
        "- **CLARIFY BROAD REQUESTS:** If the user asks for \"all data\", \"show the table\", or makes a similarly broad request that implies fetching the entire table without refinement:\n",
        "    - Your 'plan' step should recognize this is too broad.\n",
        "    - Your next step should be 'output', not 'action:query_hana'.\n",
        "    - In the 'output' step's 'content', politely explain that you cannot fetch the entire table and ask the user to be more specific. Suggest options like:\n",
        "        - Applying filters (e.g., \"for a specific product like 'Eclairs'?\", \"in a particular country like 'USA'?\", \"within a date range?\").\n",
        "        - Requesting a summary (e.g., \"total sales per product?\", \"count of sales per country?\").\n",
        "        - Specifying the exact columns they need (if it's a small, targeted number).\n",
        "    - **Example Clarification Output JSON:** '{\"step\": \"output\", \"content\": \"Fetching the entire sales table isn't practical. Could you please help me narrow it down? For example, are you interested in sales for a specific product, a particular country, a date range, or perhaps a summary like total sales per product?\", \"function\": null, \"input\": null}'\n",
        "- **PRIORITIZE SPECIFICITY:** Always aim to generate queries that are targeted to the user's specific question using 'WHERE', 'GROUP BY', 'SUM'/'AVG'/'COUNT', and/or 'LIMIT'. Only select the specific columns needed to answer the question or create the requested chart.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "CHOCOLATE_SALES TABLE:\n",
        "\n",
        "Columns:\n",
        "- \"Sales Person\" (string)\n",
        "- \"Country\" (string)\n",
        "- \"Product\" (string)\n",
        "- \"Date\" (date, format YYYYMMDD)\n",
        "- \"Amount\" (float - **potential issue: might be TEXT in DB, use CAST(\"Amount\" AS DECIMAL(18, 2)) in SUM/AVG if query fails**)\n",
        "- \"Boxes Shipped\" (integer)\n",
        "\n",
        "\n",
        "SQL Guidelines:\n",
        "- Always select from table: CHOCOLATE_SALES\n",
        "- Use double quotes for all column names: e.g., \"Country\", \"Amount\"\n",
        "- Use GROUP BY, ORDER BY, SUM, AVG, COUNT, LIMIT etc. as needed.\n",
        "- Use aliases for aggregated columns (e.g., 'SUM(\"Amount\") AS \"Total Amount\"'). Make sure these aliases match the 'x_col'/'y_col' used in 'create_chart'. Use double quotes for aliases too if they contain spaces or are reserved words.\n",
        "- Use ORDER BY and LIMIT for top-N queries.\n",
        "- **If SUM or AVG on \"Amount\" fails with a datatype error, regenerate the SQL using 'CAST(\"Amount\" AS DECIMAL(18, 2))' inside the aggregate function.**\n",
        "- **When filtering on string columns like \"Product\" or \"Sales Person\", use the 'LIKE' operator with '%' wildcards around the user's term (e.g., 'WHERE \"Product\" LIKE '%Mint Chip%'') instead of an exact match ('='), unless the user specifically requests an exact match (e.g., \"sales person is exactly 'John Doe'\"). Case sensitivity might depend on HANA settings, 'UPPER()' can be used on both sides for case-insensitive matching if needed (e.g. 'WHERE UPPER(\"Product\") LIKE UPPER('%Mint Chip%')').**\n",
        "- Output **only valid SQL**, no explanations.\n",
        "- Generate only syntactically correct and optimized SQL.\n",
        "- **IMPORTANT FOR STRING FILTERING:** When filtering on string columns like \"Product\", \"Country\", or \"Sales Person\" based on user input that might have inconsistent casing (e.g., 'eclairs' vs 'Eclairs', 'usa' vs 'USA'):\n",
        "    - **ALWAYS** use the 'UPPER()' function on both the database column and the user's search term within the 'LIKE' operator.\n",
        "    - **ALWAYS** wrap the user's term with ''%'' wildcards unless they explicitly ask for an exact match *and* case sensitivity (which is rare).\n",
        "    - **Example:** 'WHERE UPPER(\"Product\") LIKE UPPER('%eclairs%')'\n",
        "    - **Example for specific list:** 'WHERE UPPER(\"Product\") IN (UPPER('Mint Chip Choco'), UPPER('85% Dark Bars'))'\n",
        "    - Only omit 'UPPER()' if the user *specifically requests a case-sensitive search*.\n",
        "\n",
        "---\n",
        "\n",
        "Available tools Descriptions:\n",
        "- get_weather: Takes a city name and returns the current weather for that city.\n",
        "- run_command: Takes a *safe* shell command string (like 'ls', 'pwd') and executes it, returning the output. Use with caution.\n",
        "- query_hana: Takes a valid SQL query string for the CHOCOLATE_SALES table. Executes the query against HANA Cloud. Returns the resulting data (as a DataFrame) on success, or an error message string on failure. The system makes successful results available for subsequent steps.\n",
        "- create_chart: Takes a JSON object input with keys 'chart_type' (string: 'bar' or 'line'), 'x_col' (string: column name for X-axis matching SQL output), 'y_col' (string: column name for Y-axis matching SQL output), and 'title' (string). Uses data from the preceding successful 'query_hana' call. Returns a confirmation message with filename or an error.\n",
        "\n",
        "---\n",
        "\n",
        "Example 1: Weather\n",
        "User Query: What's the weather in Tokyo?\n",
        "Output: {\"step\":\"plan\", \"content\": \"The user wants the weather in Tokyo. I should use the get_weather tool.\", \"function\": null, \"input\": null}\n",
        "Output: {\"step\":\"action\", \"content\": \"\", \"function\":\"get_weather\", \"input\":\"Tokyo\"}\n",
        "Output: {\"step\":\"observe\", \"output\":\"The weather in Tokyo is Sunny +22¬∞C\"}\n",
        "Output: {\"step\":\"output\", \"content\":\"The current weather in Tokyo is Sunny and +22¬∞C.\", \"function\": null, \"input\": null}\n",
        "\n",
        "---\n",
        "\n",
        "Example 2: Top Sales People (Data Only)\n",
        "User Query: Show me top 5 sales people by amount.\n",
        "Output: {\"step\":\"plan\", \"content\":\"The user wants the top 5 sales people ranked by total sales amount. I need to query the HANA database.\", \"function\": null, \"input\": null}\n",
        "Output: {\"step\":\"action\", \"content\": \"\", \"function\":\"query_hana\", \"input\":\"SELECT \\\"Sales Person\\\", SUM(CAST(\\\"Amount\\\" AS DECIMAL(18,2))) AS \\\"Total Sales\\\" FROM CHOCOLATE_SALES GROUP BY \\\"Sales Person\\\" ORDER BY \\\"Total Sales\\\" DESC LIMIT 5\"}\n",
        "Output: {\"step\":\"observe\", \"output\":\"HANA query executed successfully. 5 rows retrieved. Data is available for the next step.\"}\n",
        "Output: {\"step\":\"output\", \"content\":\"Okay, I've retrieved the top 5 sales people by total sales amount. The system will now display the data table:\\n%%DATA_TABLE%%\", \"function\": null, \"input\": null}\n",
        "# Python code will replace %%DATA_TABLE%% with the actual data table from the query result.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "Example 3: Charting\n",
        "User Query: Create a bar chart showing total sales amount per country.\n",
        "Output: {\"step\":\"plan\", \"content\":\"User wants a bar chart of total sales by country. First, query data.\", \"function\": null, \"input\": null}\n",
        "Output: {\"step\":\"action\", \"content\": \"\", \"function\":\"query_hana\", \"input\":\"SELECT \\\"Country\\\", SUM(CAST(\\\"Amount\\\" AS DECIMAL(18,2))) AS \\\"Total Amount\\\" FROM CHOCOLATE_SALES GROUP BY \\\"Country\\\" ORDER BY \\\"Country\\\"\"}\n",
        "Output: {\"step\":\"observe\", \"output\":\"HANA query executed successfully. Data is available for the next step.\"}\n",
        "Output: {\"step\":\"plan\", \"content\":\"Data fetched. Now, create the bar chart using the 'Country' and 'Total Amount' columns.\", \"function\": null, \"input\": null}\n",
        "Output: {\"step\":\"action\", \"content\": \"\", \"function\":\"create_chart\", \"input\": {\"chart_type\": \"bar\", \"x_col\": \"Country\", \"y_col\": \"Total Amount\", \"title\": \"Total Sales Amount by Country\"}}\n",
        "Output: {\"step\":\"observe\", \"output\":\"Chart 'Total Sales Amount by Country' created and saved as charts/chart_Total_Sales_Amount_by_Country_1678886400.png\"}\n",
        "Output: {\"step\":\"output\", \"content\":\"Done! I've created the bar chart showing total sales amount by country. It's saved as charts/chart_Total_Sales_Amount_by_Country_1678886400.png.\", \"function\": null, \"input\": null}\n",
        "\n",
        "---\n",
        "\n",
        "Example 4: Specific Data Request (Using %%DATA_TABLE%%)\n",
        "User Query: List all sales made by 'Jehu Rudeforth' in the UK\n",
        "Output: {\"step\": \"plan\", \"content\": \"User wants to see all sales records for a specific person ('Jehu Rudeforth') in a specific country ('UK'). I need to query the CHOCOLATE_SALES table.\", \"function\": null, \"input\": null}\n",
        "Output: {\"step\": \"action\", \"content\": \"\", \"function\": \"query_hana\", \"input\": \"SELECT * FROM CHOCOLATE_SALES WHERE \\\"Sales Person\\\" LIKE '%Jehu Rudeforth%' AND \\\"Country\\\" LIKE '%UK%'\"}\n",
        "Output: {\"step\": \"observe\", \"output\": \"HANA query executed successfully. 12 rows retrieved. Data is available for the next step.\"}\n",
        "Output: {\"step\": \"output\", \"content\": \"Okay, here are the sales records for 'Jehu Rudeforth' in the UK:\\n%%DATA_TABLE%%\", \"function\": null, \"input\": null}\n",
        "\n",
        "Example 5: Top and Bottom Request\n",
        "User Query: Show the best and worst selling products by total amount.\n",
        "Output: {\"step\": \"plan\", \"content\": \"User wants the single product with the highest total sales and the single product with the lowest total sales. I need to use UNION ALL to combine two queries.\", \"function\": null, \"input\": null}\n",
        "Output: {\"step\": \"action\", \"content\": \"\", \"function\": \"query_hana\", \"input\": \"(SELECT 'Top Selling' AS \\\"Rank\\\", \\\"Product\\\", SUM(CAST(\\\"Amount\\\" AS DECIMAL(18,2))) AS \\\"Total Sales\\\" FROM CHOCOLATE_SALES GROUP BY \\\"Product\\\" ORDER BY \\\"Total Sales\\\" DESC LIMIT 1) UNION ALL (SELECT 'Worst Selling' AS \\\"Rank\\\", \\\"Product\\\", SUM(CAST(\\\"Amount\\\" AS DECIMAL(18,2))) AS \\\"Total Sales\\\" FROM CHOCOLATE_SALES GROUP BY \\\"Product\\\" ORDER BY \\\"Total Sales\\\" ASC LIMIT 1)\"}\n",
        "Output: {\"step\": \"observe\", \"output\": \"HANA query executed successfully. 2 rows retrieved. Data is available for the next step.\"}\n",
        "Output: {\"step\": \"output\", \"content\": \"Okay, here are the best and worst selling products by total sales amount:\\n%%DATA_TABLE%%\", \"function\": null, \"input\": null}\n",
        "\n",
        "\n",
        "Example 6: Handling Broad Request**\n",
        "User Query: Show me all the data in the chocolate sales table.\n",
        "Output: {\"step\":\"plan\", \"content\":\"The user is asking to see the entire CHOCOLATE_SALES table. This is too broad according to the guidelines. I must ask for clarification instead of querying.\", \"function\": null, \"input\": null}\n",
        "Output: {\"step\":\"output\", \"content\":\"Fetching the entire sales table isn't practical as it can be very large. Could you please help me narrow down what you're looking for? For example, are you interested in sales data for a specific product, a particular country, a certain date range, or perhaps a summary like total sales per product?\", \"function\": null, \"input\": null}\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "# Start of Streamlit App UI and Logic\n",
        "\n",
        "st.set_page_config(layout=\"wide\")\n",
        "st.title(\"ü§ñ HANA AI Assistant\")\n",
        "\n",
        "\n",
        "#Start of Check Connections\n",
        "if hana_conn_error:\n",
        "    st.sidebar.error(f\"HANA Connection Failed: {hana_conn_error}\")\n",
        "if openai_client_error:\n",
        "    st.sidebar.error(f\"OpenAI Client Failed: {openai_client_error}\")\n",
        "if not hana_conn_error and not openai_client_error:\n",
        "    st.sidebar.success(\"HANA & OpenAI Connections Successful!\")\n",
        "\n",
        "if HANA_CONNECTION is None or client is None:\n",
        "     st.error(\"connection failed.\")\n",
        "     st.stop()\n",
        "#End of Check Connections\n",
        "\n",
        "# Initialize session state variables\n",
        "if 'messages' not in st.session_state:\n",
        "    st.session_state.messages = [{\"role\": \"system\", \"content\": system_prompt}]\n",
        "if 'last_query_result_df' not in st.session_state:\n",
        "    st.session_state.last_query_result_df = None\n",
        "if 'processing' not in st.session_state:\n",
        "    st.session_state.processing = False\n",
        "if 'final_output_message' not in st.session_state:\n",
        "    st.session_state.final_output_message = None\n",
        "if 'status_messages' not in st.session_state:\n",
        "    st.session_state.status_messages = []\n",
        "if 'chart_filename' not in st.session_state:\n",
        "    st.session_state.chart_filename = None\n",
        "\n",
        "\n",
        "with st.form(\"query_form\"):\n",
        "    user_query = st.text_area(\n",
        "        \"Enter your query:\",\n",
        "        placeholder=\"e.g., Show top 5 products by sales, Create a sales chart by country, What's the weather in London?\",\n",
        "        height=100,\n",
        "        key=\"user_query_input\"\n",
        "    )\n",
        "    submit_button = st.form_submit_button(\"Submit Query\")\n",
        "\n",
        "\n",
        "\n",
        "st.write(\"Or try an example:\")\n",
        "cols = st.columns(3)\n",
        "\n",
        "output_placeholder = st.empty()\n",
        "\n",
        "\n",
        "# Expander Widget\n",
        "def display_output():\n",
        "    \"\"\"Displays the final output clearly and hides details in an expander.\"\"\"\n",
        "    with output_placeholder.container():\n",
        "        st.subheader(\"Assistant Response:\")\n",
        "        final_message_content = None\n",
        "        final_message_type = None\n",
        "        details_messages = []\n",
        "        processed_message_ids = set()\n",
        "\n",
        "\n",
        "        status_messages_copy = list(st.session_state.status_messages)\n",
        "\n",
        "\n",
        "        terminating_error = None\n",
        "        for i, (msg_type, msg_content) in enumerate(status_messages_copy):\n",
        "            msg_id = (i, msg_type, str(msg_content)) # Creates a unique ID\n",
        "\n",
        "            is_final_markdown = (msg_type == \"markdown\" and isinstance(st.session_state.final_output_message, str) and msg_content == st.session_state.final_output_message)\n",
        "            is_final_type = (msg_type == \"final\")\n",
        "\n",
        "            is_terminating_error = (msg_type == \"error\" and st.session_state.get('task_complete', False))\n",
        "\n",
        "            if is_final_markdown or is_final_type:\n",
        "                final_message_content = msg_content\n",
        "                final_message_type = msg_type\n",
        "                processed_message_ids.add(msg_id)\n",
        "\n",
        "            if is_terminating_error:\n",
        "                 terminating_error = msg_content\n",
        "                 processed_message_ids.add(msg_id)\n",
        "\n",
        "\n",
        "\n",
        "        if terminating_error:\n",
        "             st.error(terminating_error)\n",
        "        elif final_message_content:\n",
        "             if final_message_type == \"markdown\":\n",
        "                 st.markdown(final_message_content, unsafe_allow_html=True)\n",
        "             else:\n",
        "                 st.markdown(f\"**Final Answer:**\\n\\n{final_message_content}\")\n",
        "\n",
        "\n",
        "        if st.session_state.chart_filename and os.path.exists(st.session_state.chart_filename):\n",
        "             st.image(st.session_state.chart_filename)\n",
        "\n",
        "             if final_message_content and st.session_state.chart_filename not in final_message_content:\n",
        "                  st.caption(f\"(Chart saved as: {st.session_state.chart_filename})\")\n",
        "             elif not final_message_content and not terminating_error:\n",
        "                  st.success(f\"Chart created and saved as {st.session_state.chart_filename}\")\n",
        "\n",
        "\n",
        "\n",
        "        for i, (msg_type, msg_content) in enumerate(status_messages_copy):\n",
        "            msg_id = (i, msg_type, str(msg_content))\n",
        "            is_task_complete_success = (msg_type == \"success\" and \"Task Complete\" in str(msg_content))\n",
        "\n",
        "\n",
        "            if msg_id not in processed_message_ids and not is_task_complete_success:\n",
        "                 details_messages.append((msg_type, msg_content))\n",
        "\n",
        "\n",
        "        if details_messages:\n",
        "            with st.expander(\"Show Execution Details\"):\n",
        "                for status_type, msg_content in details_messages:\n",
        "                    if status_type == \"info\": st.info(msg_content)\n",
        "                    elif status_type == \"warning\": st.warning(msg_content)\n",
        "                    elif status_type == \"error\": st.error(msg_content)\n",
        "                    elif status_type == \"success\": st.success(msg_content)\n",
        "                    elif status_type == \"write\": st.write(msg_content)\n",
        "                    elif status_type == \"markdown\": st.markdown(msg_content, unsafe_allow_html=True)\n",
        "                    elif status_type == \"dataframe\":\n",
        "                        if isinstance(msg_content, pd.DataFrame):\n",
        "                            st.write(\"üìä Sample Data (first 10 rows):\")\n",
        "                            st.dataframe(msg_content.head(10))\n",
        "                        else:\n",
        "                            st.warning(\"Received 'dataframe' status but content is not a DataFrame.\")\n",
        "                    elif status_type == \"dataframe_empty\": st.write(\"Query returned no data.\")\n",
        "\n",
        "\n",
        "# Processing Logic\n",
        "\n",
        "if submit_button and user_query and not st.session_state.processing:\n",
        "    st.session_state.processing = True\n",
        "    st.session_state.task_complete = False\n",
        "    st.session_state.messages = [{\"role\": \"system\", \"content\": system_prompt}]\n",
        "    st.session_state.messages.append({\"role\": \"user\", \"content\": user_query})\n",
        "    st.session_state.last_query_result_df = None\n",
        "    st.session_state.final_output_message = None\n",
        "    st.session_state.status_messages = []\n",
        "    st.session_state.chart_filename = None\n",
        "\n",
        "    with st.spinner(\"ü§ñ Assistant thinking...\"):\n",
        "        max_steps = 10\n",
        "        step_count = 0\n",
        "\n",
        "\n",
        "        while not st.session_state.task_complete and step_count < max_steps:\n",
        "            step_count += 1\n",
        "            current_status = []\n",
        "\n",
        "\n",
        "            try:\n",
        "                #Call the OpenAI API\n",
        "                response = client.chat.completions.create(\n",
        "                    model='gpt-4o',\n",
        "                    response_format={\"type\": \"json_object\"},\n",
        "                    messages=st.session_state.messages,\n",
        "                    temperature=0.1\n",
        "                )\n",
        "                assistant_response_content = response.choices[0].message.content\n",
        "                st.session_state.messages.append({\"role\": \"assistant\", \"content\": assistant_response_content})\n",
        "\n",
        "            except Exception as e:\n",
        "                error_msg = f\"‚ùå Error calling OpenAI API: {e}\"\n",
        "                current_status.append((\"error\", error_msg))\n",
        "                st.session_state.task_complete = True\n",
        "                st.session_state.final_output_message = error_msg\n",
        "                st.session_state.status_messages.extend(current_status)\n",
        "                st.session_state.processing = False\n",
        "                st.rerun()\n",
        "\n",
        "            if st.session_state.task_complete: continue\n",
        "\n",
        "            try:\n",
        "\n",
        "                parsed_output = json.loads(assistant_response_content)\n",
        "                step = parsed_output.get(\"step\")\n",
        "\n",
        "                if step == \"plan\":\n",
        "                    plan_content = parsed_output.get('content', '...')\n",
        "                    current_status.append((\"info\", f\"üß† Plan: {plan_content}\"))\n",
        "\n",
        "                elif step == \"action\":\n",
        "                    tool_name = parsed_output.get(\"function\")\n",
        "                    tool_input = parsed_output.get(\"input\")\n",
        "                    current_status.append((\"write\", f\"üé¨ Action: Calling tool '{tool_name}'...\"))\n",
        "\n",
        "                    if not tool_name or tool_name not in available_tools:\n",
        "                        tool_output = f\"Error: Tool '{tool_name}' unavailable/unspecified.\"\n",
        "                        current_status.append((\"error\", f\"‚ùå {tool_output}\"))\n",
        "                        st.session_state.messages.append({\"role\": \"assistant\", \"content\": json.dumps({\"step\": \"observe\", \"output\": tool_output})})\n",
        "                    else:\n",
        "                        tool_function = available_tools[tool_name][\"fn\"]\n",
        "                        try:\n",
        "                            tool_output = None\n",
        "                            if tool_name == \"query_hana\":\n",
        "                                sql_to_execute = str(tool_input) if isinstance(tool_input, str) else str(tool_input)\n",
        "                                current_status.append((\"markdown\", f\"**Generated SQL:**\\n'''sql\\n{sql_to_execute}\\n'''\"))\n",
        "                                query_result = tool_function(sql_to_execute)\n",
        "                                if isinstance(query_result, pd.DataFrame):\n",
        "                                    st.session_state.last_query_result_df = query_result\n",
        "                                    tool_output = f\"HANA query executed. Rows: {len(query_result)}.\"\n",
        "                                    if not query_result.empty: current_status.append((\"dataframe\", query_result))\n",
        "                                    else: current_status.append((\"dataframe_empty\", None))\n",
        "                                else:\n",
        "                                    st.session_state.last_query_result_df = None\n",
        "                                    tool_output = query_result\n",
        "                                    current_status.append((\"error\", f\"HANA Query Observation: {tool_output}\"))\n",
        "\n",
        "                            elif tool_name == \"create_chart\":\n",
        "                                if not isinstance(tool_input, dict): tool_output = \"Error: Input must be JSON.\"\n",
        "                                elif st.session_state.last_query_result_df is None: tool_output = \"Error: No data.\"\n",
        "                                elif st.session_state.last_query_result_df.empty: tool_output = \"Error: Data is empty.\"\n",
        "                                else: tool_output = tool_function(data=st.session_state.last_query_result_df, chart_params=tool_input)\n",
        "\n",
        "                                if isinstance(tool_output, str) and tool_output.startswith(\"Chart \"):\n",
        "                                    try:\n",
        "                                        filename = tool_output.split(\" saved as \")[-1]\n",
        "                                        if os.path.exists(filename):\n",
        "                                            st.session_state.chart_filename = filename\n",
        "                                            current_status.append((\"image\", filename))\n",
        "                                        else: current_status.append((\"warning\", f\"Chart file not found: {filename}\"))\n",
        "                                    except Exception: current_status.append((\"warning\", \"Filename parse error.\"))\n",
        "                                else: current_status.append((\"error\", f\"Chart Creation Observation: {tool_output}\"))\n",
        "\n",
        "                            else:\n",
        "                                tool_output = tool_function(tool_input)\n",
        "\n",
        "                                if \"error\" in str(tool_output).lower(): current_status.append((\"warning\", f\"Tool Obs: {tool_output}\"))\n",
        "                                else: current_status.append((\"write\", f\"Tool Obs: {tool_output}\"))\n",
        "\n",
        "\n",
        "                            if tool_output is None: tool_output = \"Tool action complete.\"\n",
        "                            st.session_state.messages.append({\"role\": \"assistant\", \"content\": json.dumps({\"step\": \"observe\", \"output\": str(tool_output)})})\n",
        "\n",
        "                        except Exception as tool_e:\n",
        "                            tool_output = f\"Critical Error executing {tool_name}: {tool_e}\"\n",
        "                            current_status.append((\"error\", f\"‚ùå {tool_output}\"))\n",
        "                            st.session_state.messages.append({\"role\": \"assistant\", \"content\": json.dumps({\"step\": \"observe\", \"output\": tool_output})})\n",
        "\n",
        "\n",
        "                elif step == \"output\":\n",
        "                    final_content = parsed_output.get('content', \"...\")\n",
        "                    placeholder = \"%%DATA_TABLE%%\"\n",
        "                    st.session_state.task_complete = True\n",
        "\n",
        "                    if placeholder in final_content:\n",
        "                        if st.session_state.last_query_result_df is not None and not st.session_state.last_query_result_df.empty:\n",
        "                            try:\n",
        "                                data_markdown = st.session_state.last_query_result_df.to_markdown(index=False)\n",
        "                                formatted_content = final_content.replace(placeholder, f\"\\n'''markdown\\n{data_markdown}\\n'''\\n\", 1)\n",
        "                            except Exception:\n",
        "                                data_string = st.session_state.last_query_result_df.to_string(index=False, max_rows=20)\n",
        "                                formatted_content = final_content.replace(placeholder, f\"\\n'''\\n{data_string}\\n'''\\n\", 1)\n",
        "                            st.session_state.final_output_message = formatted_content\n",
        "                            current_status.append((\"markdown\", formatted_content))\n",
        "                        elif st.session_state.last_query_result_df is not None:\n",
        "                            formatted_content = final_content.replace(placeholder, \"\\n(Query returned no rows.)\\n\", 1)\n",
        "                            st.session_state.final_output_message = formatted_content\n",
        "                            current_status.append((\"markdown\", formatted_content))\n",
        "                        else:\n",
        "                            formatted_content = final_content.replace(placeholder, \"\\n(No data available.)\\n\", 1)\n",
        "                            st.session_state.final_output_message = formatted_content\n",
        "                            current_status.append((\"markdown\", formatted_content))\n",
        "                    else:\n",
        "                        st.session_state.final_output_message = final_content\n",
        "                        current_status.append((\"final\", final_content))\n",
        "\n",
        "\n",
        "                    if st.session_state.chart_filename and isinstance(st.session_state.final_output_message, str) and st.session_state.chart_filename not in st.session_state.final_output_message:\n",
        "                         st.session_state.final_output_message += f\"\\n(Chart: {st.session_state.chart_filename})\"\n",
        "\n",
        "                         if current_status:\n",
        "                             last_type, _ = current_status[-1]\n",
        "                             if last_type in [\"markdown\", \"final\"]: current_status[-1] = (last_type, st.session_state.final_output_message)\n",
        "                             else: current_status.append((\"final\", st.session_state.final_output_message))\n",
        "\n",
        "                    current_status.append((\"success\", \"‚úÖ Task Complete.\"))\n",
        "\n",
        "                else:\n",
        "                    error_msg = f\"‚ùì Unknown step: '{step}'\"\n",
        "                    current_status.append((\"error\", error_msg))\n",
        "                    st.session_state.messages.append({\"role\": \"assistant\", \"content\": json.dumps({\"step\": \"observe\", \"output\": error_msg})})\n",
        "                    st.session_state.task_complete = True\n",
        "                    st.session_state.final_output_message = error_msg\n",
        "\n",
        "            except json.JSONDecodeError as json_e:\n",
        "                error_msg = f\"‚ùå Invalid JSON: {assistant_response_content}\\nError: {json_e}\"\n",
        "                current_status.append((\"error\", error_msg))\n",
        "                st.session_state.task_complete = True\n",
        "                st.session_state.final_output_message = error_msg\n",
        "            except Exception as proc_e:\n",
        "                 error_msg = f\"‚ùå Processing error: {proc_e}\"\n",
        "                 current_status.append((\"error\", error_msg))\n",
        "                 st.session_state.task_complete = True\n",
        "                 st.session_state.final_output_message = error_msg\n",
        "\n",
        "\n",
        "            st.session_state.status_messages.extend(current_status)\n",
        "\n",
        "\n",
        "\n",
        "        if not st.session_state.task_complete and step_count >= max_steps:\n",
        "            st.warning(\"‚ö†Ô∏è Assistant reached maximum processing steps.\")\n",
        "            st.session_state.status_messages.append((\"warning\", \"Reached max steps.\"))\n",
        "            st.session_state.task_complete = True\n",
        "\n",
        "\n",
        "    #Processing Finished\n",
        "    st.session_state.processing = False\n",
        "\n",
        "    display_output()\n",
        "\n",
        "elif not st.session_state.processing:\n",
        "    display_output()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uEzfc181jMEw",
        "outputId": "79c92c1e-8254-4299-e66e-6513ef85e7f2"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyngrok --quiet\n",
        "\n",
        "from pyngrok import ngrok\n",
        "import os\n",
        "\n",
        "\n",
        "ngrok.kill()\n",
        "\n",
        "\n",
        "\n",
        "NGROK_AUTH_TOKEN = \"Your NGROK AUTH Token\"\n",
        "if NGROK_AUTH_TOKEN:\n",
        "  ngrok.set_auth_token(NGROK_AUTH_TOKEN)\n",
        "else:\n",
        "  print(\"Consider setting an ngrok authtoken for better stability.\")\n",
        "\n",
        "##Runs in background\n",
        "!nohup streamlit run app.py --server.port 8501 --server.headless true > streamlit.log &\n",
        "\n",
        "import time\n",
        "time.sleep(5)\n",
        "\n",
        "\n",
        "try:\n",
        "    public_url = ngrok.connect(8501)\n",
        "\n",
        "    print(\"üöÄ Streamlit App is live! Click the link below:\")\n",
        "    print(public_url)\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error establishing ngrok tunnel: {e}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZhGgbTK4jOD2",
        "outputId": "02eb694e-b0d2-42b7-b033-e3585fe07184"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nohup: redirecting stderr to stdout\n",
            "üöÄ Streamlit App is live! Click the link below:\n",
            "NgrokTunnel: \"https://b53f-35-245-246-49.ngrok-free.app\" -> \"http://localhost:8501\"\n"
          ]
        }
      ]
    }
  ]
}